from openai import OpenAI
import os
import traceback
from dotenv import load_dotenv

load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def gpt_comment(causes, main_emotion=None):
    if not causes:
        return "ì˜¤ëŠ˜ í•˜ë£¨ íŠ¹ë³„í•œ ê°ì • ì›ì¸ì„ ì°¾ì§€ ëª»í–ˆì–´ìš”. ë‚´ì¼ì€ ì¡°ê¸ˆ ë” ë§ˆìŒì„ ë“¤ì—¬ë‹¤ë³´ëŠ” í•˜ë£¨ê°€ ë˜ê¸¸ ë°”ëë‹ˆë‹¤."

    print("\n[ğŸ”¥ ê°ì • ì›ì¸ ë””ë²„ê·¸ ì¶œë ¥]")
    for i, (sentence, cause) in enumerate(causes, 1):
        print(f"{i}. \"{sentence}\" â†’ ì›ì¸: {cause}")

    prompt = "ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì¼ê¸°ì—ì„œ ì¶”ì¶œí•œ ê°ì • ì›ì¸ì…ë‹ˆë‹¤:\n"
    for i, (sentence, cause) in enumerate(causes, 1):
        prompt += f"{i}. \"{sentence}\" â†’ ì›ì¸: {cause}\n"

    if main_emotion:
        prompt += f"\nì‚¬ìš©ìì˜ ì˜¤ëŠ˜ ì£¼ìš” ê°ì •ì€ \"{main_emotion}\"ì…ë‹ˆë‹¤.\n"

    prompt += (
        "\nì´ëŸ¬í•œ ê°ì • ì›ì¸ê³¼ ì£¼ìš” ê°ì •ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ë”°ëœ»í•œ ì¡°ì–¸ì„ ê³µë°± í¬í•¨ 300ê¸€ì ì´ë‚´, ë‘ ë¬¸ë‹¨ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. "
        "ê°ì •ì˜ ì›ì¸ì„ ë°˜ë“œì‹œ ì–¸ê¸‰í•´ì•¼ í•˜ë©°, ê°ì • ìƒíƒœì— ê³µê°í•˜ëŠ” ë”°ëœ»í•œ ë§íˆ¬ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. "
        "ì‚¬ìš©ìê°€ ì•ìœ¼ë¡œ ì–´ë–»ê²Œ í•˜ë©´ ì¢‹ì„ì§€ ì¡°ì–¸ë„ í•´ì£¼ì„¸ìš”. "
        "ë‘ ê°œì˜ ë¬¸ë‹¨ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ë˜ê²Œ í•´ì£¼ê³  ê¸€ì ìˆ˜ ì œí•œì„ ê¼­ ì§€ì¼œì£¼ì„¸ìš”.\n"
    )

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            timeout=10       
        )
        return response.choices[0].message.content.strip()

    except Exception as e:
        print("GPT API í˜¸ì¶œ ì¤‘ ì˜ˆì™¸ ë°œìƒ:", e)
        traceback.print_exc()
        return "AI ì‘ë‹µì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
